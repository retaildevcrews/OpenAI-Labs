{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient, SearchIndexingBufferedSender\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from pdfminer.high_level import extract_text\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "from azure.search.documents.indexes.models import (\n",
    "    ExhaustiveKnnVectorSearchAlgorithmConfiguration,\n",
    "    ExhaustiveKnnParameters,\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SearchIndex,\n",
    "    SemanticConfiguration,\n",
    "    PrioritizedFields,\n",
    "    SemanticField,\n",
    "    SearchField,\n",
    "    SemanticSettings,\n",
    "    VectorSearch,\n",
    "    HnswVectorSearchAlgorithmConfiguration,\n",
    "    HnswParameters,\n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    VectorSearchProfile,\n",
    "    AzureOpenAIParameters,\n",
    "    AzureOpenAIVectorizer,\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    VectorSearch,\n",
    "    HnswVectorSearchAlgorithmConfiguration,\n",
    "    ExhaustiveKnnVectorSearchAlgorithmConfiguration,\n",
    "    ExhaustiveKnnParameters,\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SearchIndex,\n",
    "    SemanticConfiguration,\n",
    "    PrioritizedFields,\n",
    "    SemanticField,\n",
    "    SearchField,\n",
    "    SemanticSettings, \n",
    "    VectorSearch,\n",
    "    HnswVectorSearchAlgorithmConfiguration,\n",
    "    HnswParameters,\n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    VectorSearchProfile,\n",
    "    AzureOpenAIParameters,\n",
    "    AzureOpenAIVectorizer,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Additional Imports\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from typing import Callable\n",
    "import io\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://search-box.search.windows.net\n",
      "my-rag\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "storage_url = f\"https://{os.getenv('AZURE_STORAGE_ACCOUNT_NAME')}.blob.core.windows.net/\"\n",
    "storage_key = os.getenv(\"AZURE_STORAGE_ACCOUNT_KEY\")\n",
    "storage_container_name = os.getenv(\"AZURE_STORAGE_BLOB_CONTAINER\")\n",
    "model: str = \"text-embedding-ada-002\" \n",
    "credential = AzureKeyCredential(key)\n",
    "print(service_endpoint)\n",
    "print(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " my-rag created\n"
     ]
    }
   ],
   "source": [
    "# Create a search index\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=service_endpoint, credential=credential)\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchableField(name=\"title\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"category\", type=SearchFieldDataType.String,\n",
    "                    filterable=True),\n",
    "    SearchField(name=\"titleVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_profile=\"myHnswProfile\"),\n",
    "    SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_profile=\"myHnswProfile\"),\n",
    "]\n",
    "\n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswVectorSearchAlgorithmConfiguration(\n",
    "            name=\"myHnsw\",\n",
    "            kind=VectorSearchAlgorithmKind.HNSW,\n",
    "            parameters=HnswParameters(\n",
    "                m=4,\n",
    "                ef_construction=400,\n",
    "                ef_search=500,\n",
    "                metric=\"cosine\"\n",
    "            )\n",
    "        ),\n",
    "        ExhaustiveKnnVectorSearchAlgorithmConfiguration(\n",
    "            name=\"myExhaustiveKnn\",\n",
    "            kind=VectorSearchAlgorithmKind.EXHAUSTIVE_KNN,\n",
    "            parameters=ExhaustiveKnnParameters(\n",
    "                metric=\"cosine\"\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"myHnswProfile\",\n",
    "            algorithm=\"myHnsw\",\n",
    "            vectorizer=\"myOpenAI\"\n",
    "        ),\n",
    "        VectorSearchProfile(\n",
    "            name=\"myExhaustiveKnnProfile\",\n",
    "            algorithm=\"myExhaustiveKnn\",\n",
    "            vectorizer=\"myOpenAI\"\n",
    "        )\n",
    "    ],\n",
    "    vectorizers=[\n",
    "        AzureOpenAIVectorizer(\n",
    "            name=\"myOpenAI\",\n",
    "            kind=\"azureOpenAI\",\n",
    "            azure_open_ai_parameters=AzureOpenAIParameters(\n",
    "                resource_uri=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "                deployment_id=model,\n",
    "                api_key=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "            )\n",
    "    )  \n",
    "]  \n",
    "\n",
    ")\n",
    "\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=PrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        prioritized_keywords_fields=[SemanticField(field_name=\"category\")],\n",
    "        prioritized_content_fields=[SemanticField(field_name=\"content\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_settings = SemanticSettings(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields,\n",
    "                    vector_search=vector_search, semantic_settings=semantic_settings)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### function for breaking up document into different chunks\n",
    "\n",
    "def split_text(text, chunk_size: int, chunk_overlap: int = 0, length_function: Callable[[str], int] = len):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = chunk_size,\n",
    "        chunk_overlap = chunk_overlap,\n",
    "        length_function = length_function\n",
    "    )\n",
    "    split_text = text_splitter.create_documents([text])\n",
    "    \n",
    "    return split_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found DTO FAQ.pdf\n",
      "Uploaded 31 chunks for DTO FAQ.pdf\n",
      "Found DTO Overview.pdf\n",
      "Uploaded 13 chunks for DTO Overview.pdf\n",
      "Found DTO Quick Guide.pdf\n",
      "Uploaded 4 chunks for DTO Quick Guide.pdf\n",
      "Found Vacation and Holidays - Hourly_Non-exempt Corporate Employees.pdf\n",
      "Uploaded 14 chunks for Vacation and Holidays - Hourly_Non-exempt Corporate Employees.pdf\n"
     ]
    }
   ],
   "source": [
    "# Embed and Upload Blobs to Azure Cognitive Search\n",
    "import tempfile\n",
    "import uuid\n",
    "\n",
    "blob_client = BlobServiceClient(\n",
    "   account_url=storage_url,\n",
    "   credential=storage_key\n",
    ")\n",
    "\n",
    "raw_files_container = blob_client.get_container_client(storage_container_name)\n",
    "\n",
    "filenames = raw_files_container.list_blob_names()\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "def generate_embeddings(text):\n",
    "    response = openai.embeddings.create(\n",
    "        input=text,model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    embeddings = response.data[0].embedding\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "chunk_size = 1000\n",
    "chunk_overlap = 0\n",
    "vector_documents = []\n",
    "for filename in filenames:\n",
    "  # Loading file and extracting contents\n",
    "  rawFileBinary = raw_files_container.download_blob(filename).readall()\n",
    "  blob_stream = io.BytesIO(rawFileBinary)\n",
    "  contents = extract_text(blob_stream)\n",
    "\n",
    "  chunks = split_text(contents, chunk_size, chunk_overlap)\n",
    "\n",
    "  print(f\"Found {filename}\")\n",
    "\n",
    "  for i, chunk in enumerate(chunks):\n",
    "    chunk = chunk.page_content\n",
    "    vector_document = {\n",
    "      \"id\": base64.urlsafe_b64encode(filename.encode('utf-8')),\n",
    "      \"title\": filename,\n",
    "      \"content\": chunk,\n",
    "      \"category\": \"hr docs\",\n",
    "      \"titleVector\": generate_embeddings(filename),\n",
    "      \"contentVector\": generate_embeddings(chunk),\n",
    "    }\n",
    "    vector_documents.append(vector_document)\n",
    "  print(f\"Uploaded {i+1} chunks for {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 62 chunks\n"
     ]
    }
   ],
   "source": [
    "search_client = SearchClient(endpoint=service_endpoint, index_name=index_name, credential=credential)\n",
    "print(f\"Uploaded {len(vector_documents)} chunks\") \n",
    "result = search_client.merge_or_upload_documents(vector_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': 'hr docs', 'content': 'Planning for and using DTO\\n\\nEmployee Responsibilities\\n\\nManager Responsibilities\\n\\n• Request DTO from your manager, ideally at least 2–3 \\n\\n• Encourage teams to proactively plan time off. \\n\\nweeks in advance. \\n\\n• Get your manager’s approval before taking DTO. \\n\\n• Once your DTO is approved, let your team know via \\nnon-blocking Outlook or Teams calendar invites or \\nanother method agreed upon by your team. \\n\\n• Plan ahead and help coordinate coverage while you’re \\n\\nout.\\n\\n• Evaluate and approve/decline time-off requests. \\n\\n• Be consistent when evaluating requests using the \\n\\ncriteria outlined above.\\n\\n• If the business cannot support a request, work with \\nthe employee to find a different window for their \\ntime off.\\n\\nResources\\n• DTO FAQ\\n\\n• DTO Policy\\n\\n• Time Away Guide \\n\\n2023 Employee Quick Guide', 'title': 'DTO Quick Guide.pdf', '@search.score': 0.82576483, '@search.reranker_score': None, '@search.highlights': None, '@search.captions': None}\n",
      "Title: DTO Quick Guide.pdf\n",
      "Score: 0.82576483\n",
      "Content: Planning for and using DTO\n",
      "\n",
      "Employee Responsibilit\n",
      "Category: hr docs\n",
      "\n",
      "{'category': 'hr docs', 'content': 'You may not use DTO, but you can apply any HHTO to cover unpaid time.\\xa0\\n\\nPlease contact Benefits@microsoft.com for more information on your specific situation.\\xa0\\xa0\\n\\nResources\\xa0\\n\\nDTO Policy\\xa0\\n\\nhttps://microsoft.sharepoint.com/sites/HRweb/SitePages/FAQ_DTO.aspx?xsdata=MDV8MDF8fGJjMmUzZjdlMGZjZjQwZGJjMDgzMDhkYmUwOTMzZjVmfD… 9/10\\n\\n\\xa0\\n\\x0c11/13/23, 1:05 PM\\n\\nFrequently asked questions (FAQ) about Discretionary Time Off (DTO)\\n\\nDTO Employee Quick Guide \\xa0\\nTime Away Guide \\xa0\\n\\n\\ue8e1 \\ue8e0 Did this content help you answer your question?\\n\\nhttps://microsoft.sharepoint.com/sites/HRweb/SitePages/FAQ_DTO.aspx?xsdata=MDV8MDF8fGJjMmUzZjdlMGZjZjQwZGJjMDgzMDhkYmUwOTMzZjVmf… 10/10', 'title': 'DTO FAQ.pdf', '@search.score': 0.8190258, '@search.reranker_score': None, '@search.highlights': None, '@search.captions': None}\n",
      "Title: DTO FAQ.pdf\n",
      "Score: 0.8190258\n",
      "Content: You may not use DTO, but you can apply any HHTO to\n",
      "Category: hr docs\n",
      "\n",
      "{'category': 'hr docs', 'content': 'https://microsoft.sharepoint.com/sites/HRweb/SitePages/DTOPolicy.aspx?xsdata=MDV8MDF8fGQ1MmE3ZTQwYjk4ZTQ3MzdiMmNhMDhkYmUwOTMyZTE…\\n\\n4/5\\n\\n\\xa0\\n\\xa0\\n\\xa0\\n\\xa0\\n\\xa0\\n\\xa0\\n\\x0c11/13/23, 1:06 PM\\n\\nDiscretionary Time Off (DTO) and Holidays Policy - US Salaried/Exempt Employees\\n\\n\\ue8e1 \\ue8e0 Did this content help you answer your question?\\n\\nhttps://microsoft.sharepoint.com/sites/HRweb/SitePages/DTOPolicy.aspx?xsdata=MDV8MDF8fGQ1MmE3ZTQwYjk4ZTQ3MzdiMmNhMDhkYmUwOTMyZTE…\\n\\n5/5', 'title': 'DTO Overview.pdf', '@search.score': 0.79536057, '@search.reranker_score': None, '@search.highlights': None, '@search.captions': None}\n",
      "Title: DTO Overview.pdf\n",
      "Score: 0.79536057\n",
      "Content: https://microsoft.sharepoint.com/sites/HRweb/SiteP\n",
      "Category: hr docs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pure Vector Search\n",
    "query = \"record your DTO usage\" \n",
    "  \n",
    "search_client = SearchClient(service_endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k=3, fields=\"contentVector\")\n",
    "# Use the below query to pass in the raw vector query instead of the query vectorization\n",
    "# vector_query = RawVectorQuery(vector=generate_embeddings(query), k=3, fields=\"contentVector\")\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    ") \n",
    "  \n",
    "for result in results:\n",
    "    print(result)\n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['content'][0: 50]}\")  \n",
    "    print(f\"Category: {result['category']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
