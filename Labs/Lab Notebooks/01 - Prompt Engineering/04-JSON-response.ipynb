{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON Response\n",
    "\n",
    "\n",
    "*__NOTE:__\n",
    "For instructions on running the Jupyter Notebook that contains the labs see instructions here: <https://github.com/retaildevcrews/OpenAI-Labs>*\n",
    "\n",
    "This lab shows examples of leveraging response_format property to return results structured as a jsone object \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os module & the OpenAI Python library for calling the OpenAI API\n",
    "# please make sure you have installed required libraries via pip install -r requirements.txt\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config values\n",
    "\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "    \n",
    "# This is set to `azure`\n",
    "openai.api_type = \"azure\"\n",
    "\n",
    "# The API key for your Azure OpenAI resource.\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Setting up the deployment name\n",
    "chatgpt_model_name = os.getenv(\"CHATGPT_MODEL_GPT4\")\n",
    "\n",
    "# Currently Chat Completions API have the following versions available: 2023-03-15-preview\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Define Request to OpenAI API\n",
    "For these labs we are using the Azure OpenAI Completion API, this is different than the Chat completion API.  Information about its usage can be found here:\n",
    "(https://learn.microsoft.com/en-us/azure/cognitive-services/openai/reference#completions)\n",
    "The function defined below takes prompt and settings parameters sends the request to the endpoint and prints the text element from the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to send the prompt to the ChatGPT model\n",
    "# More info : https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions\n",
    "def send_prompt(prompt, temperature=0.5, top_p=0.5, system_message=\"you are an assistant that performs completions\"):\n",
    "    messages=[\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\":prompt}\n",
    "    ]\n",
    "    response = openai.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=chatgpt_model_name,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        response_format={\"type\":\"json_object\"}\n",
    "    )\n",
    "    response_content=response.choices[0].message.content\n",
    "    print(\"----\")\n",
    "    print(\"Settings:\")\n",
    "    print(\"temperature: \"+ str(temperature) + \" top_p: \" + str(top_p))\n",
    "    print(\"Prompt: \" + prompt)\n",
    "    print(\"Response: \")\n",
    "    print(str(response_content))\n",
    "    print(\"----\")\n",
    "    return response_content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Response Format json_object without mentioning json in system prompt\n",
    "When using json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =  \"\"\"\n",
    "Translate the following English text to French: 'Hello, how are you?\n",
    "\"\"\"\n",
    "send_prompt(prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Run with different settings\n",
    "\n",
    "In these examples we will run the single prompt using different settings for Temperature and Top_p, the first number parameter sets temperature and second sets top_p.  Feel free to play with different values or add new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =  \"\"\"\n",
    "The sky is\n",
    "\"\"\"\n",
    "send_prompt(prompt,0,0)\n",
    "\n",
    "send_prompt(prompt,0.9,0.5)\n",
    "\n",
    "send_prompt(prompt,0.5,0.5)\n",
    "\n",
    "send_prompt(prompt,0,1)\n",
    "\n",
    "send_prompt(prompt,1,0)\n",
    "\n",
    "send_prompt(prompt,1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Prompt with Instructions\n",
    "These examples provide instructions in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =  \"\"\"\n",
    "Finish the following sentence and print the entire resulting sentence:\n",
    "The sky is\n",
    "\"\"\"\n",
    "send_prompt(prompt)\n",
    "\n",
    "\n",
    "prompt =  \"\"\"\n",
    "Translate the text below to Spanish:\n",
    "Text: \"hello!\"\n",
    "\"\"\"\n",
    "send_prompt(prompt)\n",
    "\n",
    "\n",
    "prompt =  \"\"\"\n",
    "Explain lacrosse\n",
    "\"\"\"\n",
    "send_prompt(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Prompt with Context\n",
    "These examples provide instructions in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =  \"\"\"\n",
    "Question: What was OKT3 originally sourced from?\n",
    "\"\"\"\n",
    "send_prompt(prompt)\n",
    "\n",
    "\n",
    "prompt =  \"\"\"\n",
    "Answer the question based on the context below. Keep the answer short and concise. Respond \"Unsure about answer\" if not sure about the answer.\n",
    "Context: Teplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. There, scientists generated an early version of the antibody, dubbed OKT3. Originally sourced from mice, the molecule was able to bind to the surface of T cells and limit their cell-killing potential. In 1986, it was approved to help prevent organ rejection after kidney transplants, making it the first therapeutic antibody allowed for human use.\n",
    "Question: What was OKT3 originally sourced from?\n",
    "\"\"\"\n",
    "send_prompt(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Prompt with JSON response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =  \"\"\"\n",
    "Question: What was OKT3 originally sourced from?\n",
    "\"\"\"\n",
    "send_prompt(prompt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc180f703c9255d3d630e6d09ed4eb3355d27845db546035ce1b410f2bfa43b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
