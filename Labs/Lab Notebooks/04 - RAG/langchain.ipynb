{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "959ffae8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RAG Approach 1 (Open Source): LangChain + Pinecone \n",
    "\n",
    "In this notebook we explore the use of <b>open source and free </b> packages for building a RAG system/pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7808679-6163-4e3d-9baa-fcd6f83d2b47",
   "metadata": {},
   "source": [
    "## Imports and Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a95ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook imports\n",
    "import openai\n",
    "import os \n",
    "from langchain.llms import AzureOpenAI\n",
    "import pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "\n",
    "# Additional imports\n",
    "from utils import process_pdf\n",
    "from langchain.document_loaders import BSHTMLLoader\n",
    "from langchain.document_loaders import UnstructuredHTMLLoader\n",
    "from typing import Callable, Optional, Union\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "import time\n",
    "\n",
    "\n",
    "#loading in environment variables\n",
    "load_dotenv('./my.env')\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai.api_base= os.getenv('OPENAI_API_BASE')\n",
    "openai.api_type= \"azure\"\n",
    "openai.api_version = os.getenv('OPENAI_API_VERSION')\n",
    "\n",
    "\n",
    "#overwriting to azure open_ai environment variables\n",
    "config = dotenv_values(\"./my.env\")\n",
    "openai.api_base = config[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "openai.api_version = config[\"AZURE_OPENAI_API_VERSION\"]\n",
    "\n",
    "\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "PINECONE_ENV = os.getenv('PINECONE_ENV')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925e2744-a2d3-4f86-aa74-b7da5f6bfd67",
   "metadata": {},
   "source": [
    "## Extracting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3bcfa9-6f9d-4fe8-861d-ae9bb1cfbc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_html = 'test_doc.html'\n",
    "doc_pdf = 'test_doc.pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa9c277-1cbf-4984-a35e-46cbe0ad3bc4",
   "metadata": {},
   "source": [
    "### From a Webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2e5617-eeaa-4a15-9853-123bca61f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredHTMLLoader(doc_html)\n",
    "data = loader.load()\n",
    "html_content = data[0].page_content\n",
    "print(html_content[40:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad2d78c-dae2-47c5-abe2-ddcc7afb943d",
   "metadata": {},
   "source": [
    "### From a PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633f61d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(doc_pdf)\n",
    "data = loader.load()\n",
    "pages = len(data)\n",
    "pdf_content = ''\n",
    "\n",
    "for x in range(pages):\n",
    "    pdf_content = pdf_content + data[x].page_content\n",
    "\n",
    "print(pdf_content[40:150])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9760a1-cba0-4767-8b9d-a67dff29b794",
   "metadata": {},
   "source": [
    "## Splitting text into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e338d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text, chunk_size: int, chunk_overlap: int, length_function: Callable[[str], int] = len):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = chunk_size,\n",
    "        chunk_overlap = chunk_overlap,\n",
    "        length_function = length_function\n",
    "    )\n",
    "    split_text = text_splitter.create_documents([text])\n",
    "    \n",
    "    return split_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d071a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1000\n",
    "chunk_overlap=0\n",
    "\n",
    "#html\n",
    "split_html = split_text(html_content, chunk_size, chunk_overlap)\n",
    "print(f'Number of HTML chunks = {len(split_html)}')\n",
    "\n",
    "\n",
    "#pdf\n",
    "split_pdf = split_text(pdf_content, chunk_size, chunk_overlap)\n",
    "print(f'Number of PDF chunks = {len(split_pdf)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b95ac6c-9b95-4e7e-b022-1792c74e1ad8",
   "metadata": {},
   "source": [
    "## Create and Store Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e7260b-7ea6-41b2-94a2-1a15b1ae423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS_MODEL = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f36e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(\n",
    "    api_key = PINECONE_API_KEY,\n",
    "    environment = PINECONE_ENV\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e0fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_search(split_text: list[str], \n",
    "                         embeddings_deployment: str, index_name: str):\n",
    "\n",
    "    # creating embeddings object\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        azure_deployment=embeddings_deployment,\n",
    "        chunk_size=1) ## set to 1 because we have already split chunks\n",
    "    \n",
    "    if index_name not in pinecone.list_indexes():\n",
    "        print(\"index does not exist\", index_name)\n",
    "\n",
    "    index = pinecone.Index(index_name)\n",
    "\n",
    "    vectorstore = Pinecone(index, embeddings, '')\n",
    "\n",
    "    \n",
    "    # Batch insert the chunks into the vector store\n",
    "    batch_size = 5  # Define your preferred batch size\n",
    "    for i in range(0, len(split_text), batch_size):\n",
    "        doc = split_text[i:i + batch_size]\n",
    "        vectorstore.add_documents(doc)\n",
    "        print(f'Done with {i}')\n",
    "        \n",
    "    \n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6085671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'langchain1'\n",
    "print(f' We are using this embeddings model {EMBEDDINGS_MODEL} on this pincone {index_name}')\n",
    "vector = create_vector_search(split_html+split_pdf, EMBEDDINGS_MODEL, index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342cbc66-4cc7-4f6f-bfe4-af16c2dc1733",
   "metadata": {},
   "source": [
    "## LLM + RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36613da-21ad-4389-85a4-6126ac92f942",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_MODEL=os.getenv('AZURE_OPENAI_CHATGPT_MODEL_NAME')\n",
    "print(LLM_MODEL)\n",
    "LLM_MODEL = 'gpt-turbo'\n",
    "llm = AzureOpenAI(\n",
    "    deployment_name=LLM_MODEL,\n",
    "    model_name=LLM_MODEL\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d99703c-f9c1-43fa-a2f3-69fdf67e4c2e",
   "metadata": {},
   "source": [
    "Night Work on a Holiday \n",
    "Except for Federal Wage System employees (discussed below), employees are generally entitled \n",
    "to night pay under 5 U.S.C. 5545(a). Employees are entitled to night pay for regularly scheduled \n",
    "work at night, including actual work performed at night during holiday hours or overtime hours. \n",
    "Night pay is paid in addition to holiday premium pay, Sunday pay, or overtime pay. (See 5 CFR \n",
    "550.122(c).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d7838a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Am I entitled to Night Pay?\"\n",
    "\n",
    "docs = vector.similarity_search(question)\n",
    "\n",
    "\n",
    "print('Relevant chunk found: \\n')\n",
    "print(docs[0].page_content[0:150])\n",
    "\n",
    "\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "chain.run(input_documents=docs, question=question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1642d0e-5d0d-4bfc-a231-a8e3c1497b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Am I entitled to Night Pay? Give me a one word answer.\"\n",
    "\n",
    "docs = vector.similarity_search(question)\n",
    "\n",
    "\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "chain.run(input_documents=docs, question=question)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-svr",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
