{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON Response\n",
    "\n",
    "\n",
    "*__NOTE:__\n",
    "For instructions on running the Jupyter Notebook that contains the labs see instructions here: <https://github.com/retaildevcrews/OpenAI-Labs>*\n",
    "\n",
    "This lab shows examples of leveraging response_format property to return results structured as a json object.  This feature is available in the newest previews of gpt-4 and gpt-35.\n",
    "\n",
    "<https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/json-mode>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os module & the OpenAI Python library for calling the OpenAI API\n",
    "# please make sure you have installed required libraries via pip install -r requirements.txt\n",
    "import os\n",
    "\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config values\n",
    "\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "    \n",
    "# This is set to `azure`\n",
    "openai.api_type = \"azure\"\n",
    "\n",
    "# The API key for your Azure OpenAI resource.\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Setting up the deployment name\n",
    "chatgpt_model_name = os.getenv(\"CHATGPT_MODEL_GPT4\")\n",
    "\n",
    "# Currently Chat Completions API have the following versions available: 2023-03-15-preview\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Define Request to OpenAI API\n",
    "For these labs we are using the Azure OpenAI Completion API, this is different than the Chat completion API.  Information about its usage can be found here:\n",
    "(https://learn.microsoft.com/en-us/azure/cognitive-services/openai/reference#completions)\n",
    "The function defined below takes prompt and settings parameters sends the request to the endpoint and prints the text element from the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to send the prompt to the ChatGPT model\n",
    "# More info : https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions\n",
    "def send_prompt(prompt, temperature=0.5, top_p=0.5, system_message=\"you are an assistant that performs completions\"):\n",
    "    messages=[\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\":prompt}\n",
    "    ]\n",
    "    response = openai.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=chatgpt_model_name,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        response_format={\"type\":\"json_object\"}\n",
    "    )\n",
    "    response_content=response.choices[0].message.content\n",
    "    print(\"----\")\n",
    "    print(\"Settings:\")\n",
    "    print(\"temperature: \"+ str(temperature) + \" top_p: \" + str(top_p))\n",
    "    print(\"Prompt: \" + prompt)\n",
    "    print(\"Response: \")\n",
    "    print(str(response_content))\n",
    "    print(\"----\")\n",
    "    return response_content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Response Format json_object without mentioning json in system prompt\n",
    "When using json response the prompt must include the words json in the system message, if not, it will raise an error.  The below prompt will fail with an error stating that json is not mentioned in the system message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =  \"\"\"\n",
    "Translate the following English text to French: 'Hello, how are you?\n",
    "\"\"\"\n",
    "send_prompt(prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Response Format json_object while correctly mentioning json in system prompt\n",
    "When using json response the prompt must include the words json in the system message, if not, it will raise an error.  The below prompt will succeed because we mentioned json in the system message. NOTE - the system message doesn't have to be prescriptive, it just checks to see if the word json is included.  Try different variations to see what works and doesn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =  \"\"\"\n",
    "Translate the following English text to French: 'Hello, how are you?\n",
    "\"\"\"\n",
    "send_prompt(prompt=prompt,system_message=\"json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc180f703c9255d3d630e6d09ed4eb3355d27845db546035ce1b410f2bfa43b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
